<speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xmlns:mstts="https://www.w3.org/2001/mstts" xml:lang="en-US">
    <voice name="en-CA-ClaraNeural">
        <break time="2000ms" />
        <prosody rate="15%" pitch="0%">
        <mstts:express-as style="chat">
                Before we start I want to disclose that all voices you hear during this presentation are synthesized. 
                All voices were produced using the Azure Text to Speech service which uses AI to simulate human voices.
                All content in the presentation was made by Sameer Doshi, a cloud solutions architect at Microsoft and can be found on his GitHub under the Azure TTS repository.            
                Ok, Aria, take it away!
            <break time="150ms" />
        </mstts:express-as>
        </prosody>
        </voice>
        <voice name="en-US-AriaNeural">
        <prosody rate="10%" pitch="0%">
        <mstts:express-as style="chat">
                When I was 5 my friends and I had lots of fun during "computer time" at school.  We made the computer say silly things in a computerized voice using it's text to speech program.  Silly things like 
                <break time="200ms" />
                The cat ate the house,  
                <break time="200ms" />
            <prosody rate="0%" pitch="0%">
                The cat ate the house,  
            </prosody>
            
                Trust mee, for a five year old, that is 
            
        </mstts:express-as>
        <mstts:express-as style="cheerful">
        hilarious.
        </mstts:express-as>
        <mstts:express-as style="chat">
                <break time="200ms" />
                Since then the quality and abilities of speech to text have really improved. With Azure Text To Speech Service, TTS for short, we’ve made it easy to add speech to complex Health Care scenarios. 
                <break time="150ms" />
                After I go over technical capabilities of the TTS service, 
                <break time="50ms" />
                Gary will show you an example of TTS in Health Care,
                <break time="50ms" />
                 and Jenny will share some example TTS scenarios for Health Care and Life Sciences companies
        </mstts:express-as>
        <break time="150ms" />
        <mstts:express-as style="newscast-casual">
          The Azure Text To Speech service is one of Azure's cognitive services.  Cognitive services let people and organizations easily use AI to enhance human abilities.  
          Azure also offers human parity computer vision, speech, face, and sentiment recognition.  Along with other AI services.  
          But today let's focus on the Text-To-Speech (TTS) service. It converts written text to high quality voices synthesized  via Neural networks.  
          <break time="150ms" />
          TTS has over 200 voices in 50 languages.
          <break time="150ms" />
          Each voice's pitch and speed can be adjusted, or different styles can be used.
          For example:
          <break time="150ms" />
        </mstts:express-as>
        
        <mstts:express-as style="empathetic">
            I am an empathetic voice. 
            <break time="150ms" />
        </mstts:express-as>
        <mstts:express-as style="newscast-formal">
            I am a newscaster voice. 
        </mstts:express-as>
        <mstts:express-as style="chat">
            I am a chat voice. 
            <break time="150ms" />
        </mstts:express-as>
        
        <mstts:express-as style="cheerful">
            I am a cheerful voice. 
            <break time="150ms" />
        </mstts:express-as>
        <mstts:express-as style="newscast-casual">
            I am a casual newscaster voice. 
        </mstts:express-as>
        <mstts:express-as style="customer-service">
            I am a customer service voice. 
            <break time="150ms" />
        </mstts:express-as>
        <mstts:express-as style="chat">
            You can even train a custom voice.  
            That’s right! You can make your voice into a TTS voice!   Microsoft believes in responsible AI, so in order to create a custom voice you’ll need to fill out a form that ensures you own the rights to the voice, and that your use of the custom voice complies with Microsoft’s guidelines on the responsible use of AI.  But after that, you can quickly train a neural network to talk like you by supplying it with recordings and transcripts of you talking!  Custom voices are a great way to ensure the accents, and speech patterns that make you, or your brand's voice are replicated by the AI!
            If you want to hear a live example of  this just search for Microsoft’s partnership with BBC Radio. 
            Azure TTS is just as easy to use as other Azure Cognitive services.  
            To use, simply make direct REST calls to the service, or use an SDK in C Sharp, Objective C, Java, JavaScript, or Python.  
            Pass in the input text and the output is a compressed audio file.
            <break time="150ms" />
            But enough abstract technical talk.  Let’s turn it over to my counterpart Gary  to talk through a real-life health care use of TTS. 
         </mstts:express-as>
          </prosody>
    </voice>
    <voice xml:lang='en-US' name='en-US-GuyNeural'>
        <prosody rate="10%" pitch="-5%">
        <mstts:express-as style="newscast">   
                <break time="500ms" />
                Thanks Jenny!   
                <break time="150ms" />
                Let’s make COVID-19 information on twitter more accessible.  
                <break time="200ms" />
                Dr. Ashish Jha is the Dean of Brown University School of Public Health.  He often posts messages that are too long to fit into a single tweet, so Twitter breaks these messages into threads. 
                <break time="100ms" />
                The problem is that  OS level TTS can’t reconstitute these threads so instead of a smooth message.
                Here's what a 3 part tweet sounds like.  I've trimmed Dr. Jha's message for this example.
        </mstts:express-as>
        </prosody>
    </voice>
    <voice xml:lang='en-US' name='en-US-Benjamin'>
        <prosody rate="20%" pitch="-5%">
            “Ashish K Jha MD MPH The rising proportion of…..” 
            “Ashish K Jha MD MPH replying to Ashish K Jha MD MPH: 2/3 and the effects of …..”
            “Ashish K Jha MD MPH replying to Ashish K Jha MD MPH: 3/3 leads us to 

           
        </prosody>
        </voice>
    <voice xml:lang='en-US' name='en-US-GuyNeural'>
         <prosody rate="10%" pitch="-5%">
            <mstts:express-as style="newscast">   
                <break time="200ms" />
                 Yikes! That’s hard to understand. Using a bit of text transformation and TTS we can instead make it sound like:
                <break time="200ms" />
                 Ashish K Jha MD MPH: "The rising proportion of …. And the effects of…. leads us to … ."
                 <break time="200ms" />
                 That's much better.
                 Let's see how it works.
                 <break time="500ms" />
                 Let's hop to the Azure Portal.
                 <break time="500ms" />
                 I have all the code running as a logic app and you can find the code exported to Sameer Doshi's GitHub under the Azure TTS repo.
                 <break time="750ms" />
                 This Logic App does the following:
                <break time="150ms" />
                    It ingest tweets from Dr. Jha 
                <break time="150ms" />
                    It transforms thread text by ripping out redundant info 
                <break time="150ms" />
                    It runs the transformed text through TTS 
                <break time="150ms" />
                    It uploads the speech to blob 
                <break time="150ms" />
                    Finally it replies to the original tweet with a link to the TTS audio. 
                <break time="150ms" />
                    Follow Text to Speech on Twitter to see this logic app in action.  
                <break time="200ms" />
                Let’s take a look at the TTS step.
                You can see that it’s a simple rest call.  
                The XML is written in the Speech Synthesis Markup Language format.
                And this example is just about as complex as it gets. 
                If you look in Sameer's GitHub you can see the SSML for this entire presentation.                               
                <break time="150ms" />
                 Let me turn it over to Jenny to talk through what Health Care Life Sciences companies could do with this easy to use, awesome tech. 
            </mstts:express-as> 
        </prosody>
    </voice>
 <voice xml:lang='en-US' name='en-US-JennyNeural'>
        <prosody rate="17%" pitch="-5%">
        <mstts:express-as style="chat">
            <break time="150ms" />
            Thanks Gary. 
         <break time="100ms" />
            Gary didn’t mention that it took him less than 24 hours to go from no knowledge to the end to end app.  I bet most engineers would have similar, or faster, time to market.   But what could a Health Care or Life Sciences company do with this tech? 
            Here are 4 quick examples. 
            <break time="100ms" />
            You could just use the example I made above summarizing Tweets from your company's account. 
            <break time="150ms" />
            Or: Does your company send long emails or newsletters?  Perhaps you send a bi-weekly covid-19 update email?   Well why not publish that as a private podcast?  Then people will have one less email to read, and people could listen to it on their commute, or in true  pandemic fashion, on their exercise bike.  Keep people in your company up-to-date on lengthy topics easily.  Work for a hospital and want to keep staff up-to-date about the latest policies?  Publishing a private 3 minute podcast every week would be an efficient, easy way to reach everyone.  Or maybe you run a lab and want to let all lab users know about the new scheduling system.  Instead of an easily ignored email, quickly publish audio that explains the process.  A setup that takes in an email and publishes to a podcast library would probably take less than 24 hours to be fully implemented. 
            <break time="150ms" />
            Our third example takes the first one a bit further.  Your company could  have many people publish content as one person.  In this scenario, let’s say you’re a company that makes vaccines.  How powerful would it be to have a weekly web series where someone from research explains how your latest vaccine works.  And then, next week someone from compliance, in the same voice, explains the lengthy process to certify a vaccine as safe and effective.  Followed the next week, again, in the same voice,  someone from distribution explains the supply chain for vaccines.  All three people would submit written content that is then synthesized and presented as the one voice for your company.  No more having to green room, interview, review, and edit.  Instead content review is done up front, in writing, and only reviewed content is presented.  Changing content is as simple as cutting the old content and pasting the new content!  With custom voice you could even use your company’s branded voice- speaking with the authority of your SMEs!  
            <break time="150ms" />
            In our fourth example- there’s lots of text in the world, but we don’t need all of it at all times.  Think about a patient chart- it has name, birthdate, and full medical history.  But the doctor moving from one room to another may only need to hear the latest info about the patient she’s about to see.   An app that could TTS the latest info on a patient would allow our doctor to get a summary while walking.   
            <break time="100ms" />
        
        </mstts:express-as>
        <mstts:express-as style="assistant">
            Think about it, you have the power to make a voice say whatever you want!
            Words matter, and when you can edit what you say just like you edit a document, the sky is the limit! 
            <break time="150ms" />
        </mstts:express-as>
        </prosody>
    </voice>
    <voice xml:lang='en-US' name='en-US-GuyNeural'>
        <prosody rate="15%" pitch="-5%">
        <mstts:express-as style="chat">   
        Hi there, One last thing.  
        </mstts:express-as>
        <mstts:express-as style="empathetic">   
        While working on this I realized I could make a presentation where I never left something out, mispoke, or said something out of order.
            And while that's pretty empowering- I also realized I was working by myself.
            If there had actually been 3 co-presenters with me they would have offered valuable feedback.
            <break time="100ms" />
            So bottom line:
            <break time="100ms" /> 
            while anyone, regardless of technical ability, can use AI to enhance their own abilities, AI cannot replace people.
         <break time="150ms" /> 
                    Thanks again for watching, I hope TTS helps you and if you have any questions please feel free to contact Sameer Doshi via GitHub.
    </mstts:express-as>
    </prosody>
    </voice>
</speak>